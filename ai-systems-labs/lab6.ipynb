{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Л6: Использование Inference API для работы с моделями ИИ (Часть 2)\n",
    "\n",
    "**Inference API** - это сервис, который обеспечивает быстрый доступ к многочисленным предобученным моделями ИИ, размещенным на инфраструктуре HuggingFace. Используя его нет необходимости в загрузке модели и запуску модели локально. Таким образом можно создавать прототипы приложений для решения различных задач не переживая о вычислительных мощностях своего компьютера. \n",
    "\n",
    "**Inference API** предоставляет бесплатный и мгновенный доступ к популярным и эффективным моделями для решения следующего спектра задача:\n",
    "* Генерация текста: включает большие языковые модели и подсказки для вызова инструментов, генерируйте и экспериментируйте с высококачественными ответами.\n",
    "* Генерация изображений: легко создавайте персонализированные изображения.\n",
    "* Работа с документами.\n",
    "* Классические задачи ИИ: готовые к использованию модели для классификации текста, изображений, распознавания речи и многого другого.\n",
    "\n",
    "\n",
    "**В этой работе мы познакомимся с этим инструментом и в качестве примера создадим собственного умного ассистента для написания программного кода.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/ Подготовка среды выполнения\n",
    "На данной этапе вам наобходимо подготовить виртуальное окружение и установить все необходимые библиотеки.\n",
    "\n",
    "1. Создать и активировать (или только активировать, если ранне создавали) виртуальной окружение `python`.\n",
    "\n",
    "В терминале вводим следующие команды команды:\n",
    "\n",
    "*создаем виртуальное окружение с помощью `python-venv`*\n",
    "```\n",
    "python -m venv env\n",
    "```\n",
    "*активируем виртуальное окружение*\n",
    "```\n",
    "env\\Scripts\\activate\n",
    "```\n",
    "**Примечание.** `env` - это название вашего виртуального окружения, назвать его можете как угодно.\n",
    "\n",
    "После этого можем выбрать наш локальный интерпрететор pyhton, нажав на кнопку выше \"Select kernel\".\n",
    "\n",
    "2. Устанавливаем все необходимые библиотеки\n",
    "\n",
    "**Примечание.** Библиотеки установятся внутрь вашего виртуального окружения.\n",
    "\n",
    "Нам понадобятся библиотеки Diffusers, Transformers, Accelerate.\n",
    "\n",
    "```\n",
    "pip install transformers\n",
    "```\n",
    "Также для работы вышеперечисленных бибилиотек потребуется PyTorch:\n",
    "```\n",
    "pip install torch\n",
    "```\n",
    "Библиотека Gradio для создания web-приложения.\n",
    "```\n",
    "pip install gradio\n",
    "```\n",
    "Также для работы с изображение нам потребуется библиотека PIL (Python Image Library) `Pillow`\n",
    "```\n",
    "pip install Pillow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/ Начало рабты. Создание Inference Client\n",
    "\n",
    "Для бессерверного обращение к модели (то есть без запуска ее на своем каком-то сервере или локально) необходимо отправить запрос, используя Inference API. В результате этого запроса мы получим ответ - Inference (то есть вывод модели). Запрос можно формировать разынми способами, но в этой работе предлагается использовать Python библиотеку `huggingface_hub`. Выполните установку\n",
    "```\n",
    "pip install --upgrade huggingface_hub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта библиотека предоставляет модуль `InferenceClient`, с помощью которого создадим клиент, который будет формировать запрос на сервера Hugging Face. Импортируем этот модуль. Также импортируете Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть одно НО! Для использования Serverless Inference API необходимо иметь **токен доступа**. Чтобы его получить необходимо зарегистрироваться на сайте Hugging Face, затем перейдите на [странице создания токенов](https://huggingface.co/settings/tokens/new?globalPermissions=inference.serverless.write&tokenType=fineGrained). Создайте `fine-grained` токен с областью действия `Make calls to the serverless Inference API`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Примечание***. Не распространяйте свой токен в публичных местах, иначе он будет скопрометирован и Hugging Face его удалит! Токен можно скопировать только один раз в моменте его создания. Сохраните его где-нибудь лично у себя и используете только в коде своего приложения когда необходимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вставьте сюда сгенерированный токен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"hf_******************\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания умного ассистента, с которым можно поговорить о том о сем будем использовать модель Image-Text-to-Text генерации текста `meta-llama/Llama-3.2-11B-Vision-Instruct`. Это мультимодальная модель, способная рабоать как текстом, так и с изображениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_model = \"meta-llama/Llama-3.2-11B-Vision-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим клиента через класс `InferenceClient`, указав ему используемую модель и свой токен доступа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(model=ai_model, token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3/ Тестирование работы модели в режиме чата (`chat completion`)\n",
    "В прошлой работе мы использовали объект `client` для формирования запроса к модели ИИ и с его помщью встпуали в чат с моделью. Мы интересовались у нее про столицу государства.\n",
    "```python\n",
    "msgs = [{\"role\": \"user\", \"content\": \"What is the capital of Great Britan?\"}]\n",
    "```\n",
    "Теперь изменим наше сообщение. Передадим изображение какого-нибудь города и попросим выяснить, что это за город и какая страна. Например, передадим изображением города Вена. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [] # массив для хранения диалога"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В связи с тем, что нашее сообшение содержит теперь графические элементы, изменится структура сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = {\n",
    "    \"role\": \"user\", \n",
    "    \"content\": [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Which city and from which country is shown in the picture?\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": \"https://avatars.mds.yandex.net/i?id=107f48d281098e173fd94c4ec00bb756_l-4504543-images-thumbs&n=13\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внесем первое сообщение в диалог:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.append(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Передаем через клиента наш запрос. Также указываем максимальный размер ответного соощения `max_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = client.chat_completion(messages=msgs, max_tokens=100, stream=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем, что нам ответила модель ИИ. В ответ мы получаем json формат. Вот так вытаскивем само сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот [здесь](https://huggingface.co/docs/api-inference/tasks/chat-completion) можно почитать подробнее про организацию чата с ИИ и структуру ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшей работы необходимо сохранять историю переписки. Поэтому все сообщения (наши и модели) складываем в `msgs` по порядку. Обязательно указываем роли: Роль и контент сообщения от ИИ мы можем вытащить из структуры ответа `ans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.append({\"role\": ans.choices[0].message.role, \"content\": ans.choices[0].message.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот получается такая история переписки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь отправим наше следующее сообщение, чтобы поддержвать разговор. Поинтересуемся, какие главные достопримечательности можно посетить. Впишем в наш диалог `msgs` сообщение, но уже в более простой форме, потому что у нас текстовое сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.append({\"role\": \"user\", \"content\": \"What are the main attractions to visit in this city?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем разговор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = client.chat_completion(messages=msgs, max_tokens=200, stream=False)\n",
    "print(ans.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И также сохраняем ответ в историю переписки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.append({\"role\": ans.choices[0].message.role, \"content\": ans.choices[0].message.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание ✅\n",
    "\n",
    "Проведите небольшой диалог в таком формате с моделью ИИ. Попросите у модели распознать объекты и тест на изображении"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4/ Генерация изображений (`text_to_image`)\n",
    "\n",
    "Через Inference API можно запускать различные модели ИИ, в том числе для генерации изображений. Создадим новый клиент для работы с моделью `stabilityai/stable-diffusion-3-medium-diffusers`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = \"stabilityai/stable-diffusion-3-medium-diffusers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_client = InferenceClient(image_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете попросить сгенерировать модель изображение, переда ей какой-нибудь промт. Для мы теперь используем метод `text_to_image`. Например, попросим ИИ создать изображение в стиле Айвазовского. Промпт будет следующий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Create an image of a sea wave in the style of Aivazovsky's paintings\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отправим запрос модели. Как видим, время ожидания ответа модели на порядок меньше по сравнению с локально запушенной моделью в одной из предыдущих ЛР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = img_client.text_to_image(prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ответ. Модель возвращает изображение в формате PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5/ Создание WEB-интерфейса с помощью `Gradio`\n",
    "\n",
    "Создайте приложение Gradio в формате чата с помощью блока `gr.ChatInterface`. Так как мы планируем использовать чат не только для текста, но и для изображений, блок необходимо сделать мультмодальным, передав параметр `multimodal=True` \n",
    "\n",
    "Ему необходимо указать функцию обработки сообщений, в которую вы поместите обращение клиента к модели ИИ как это было выше. Функция принимает на вход два параметра\n",
    "* `message` - текущее сообщение, текст\n",
    "* `history` - история сообщений с чат-ботом, список из словарей, с указанием ролей\n",
    "\n",
    "Например, пусть это будет функция с названием chatbot\n",
    "```python\n",
    "def chatbot(message, history):\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера ниже приведен код \"пустышка\". При вводе сообщения попробуйте вставить изображение (можно выбрать на диске или вставить скопированное). `print(message)` покаже вам структуру сообщения. Как можете увидеть, в сообщение дается ссылка на локальное расположение файла изображения. **Но мы не можем передать модели ИИ ссылку на локальный файл, у нее просто не будет доступа к ней!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def echo(message, history):\n",
    "    print(message)\n",
    "    return \"echo\"\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=echo, \n",
    "    type=\"messages\", \n",
    "    title=\"Chat with LLM\",\n",
    "    multimodal=True\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Возможные решения:\n",
    "1. В сообщении давать только ссылку на изображение. Но в этом случае мы не будем видеть изображение в диалоге\n",
    "2. **Загружать изображение на облако и давать на него публичную ссылку**.Так как все, что мы вставляем в наше сообщение, в конечном итоге сохранятеся во временной директории на локальном диске (смотри выход блока кода выше), то мы можем загрузить изображение, например, на облачный диск (Google Drive, Яндекс.Диск) и \"расшарить\" изображение. Ниже приведен пример работы с Яндекс.Диск\n",
    "\n",
    "***Прмечание***. Данный пример и его описание сгенерировано с помощью GigaChat. Вы также можете найти свое решения с помощью ИИ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объяснение работы с Яндекс.Диск через python для загрузки изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно также загрузить изображение на Яндекс.Диск с помощью Python. Для этого мы будем использовать библиотеку `yadisk`, которая предоставляет удобный интерфейс для работы с Яндекс.Диском.\n",
    "\n",
    "### Установка библиотеки\n",
    "\n",
    "Сначала установим библиотеку `yadisk`:\n",
    "\n",
    "```bash\n",
    "pip install yadisk\n",
    "```\n",
    "\n",
    "### Код для загрузки изображения на Яндекс.Диск\n",
    "\n",
    "```python\n",
    "from yadisk import Yadisk\n",
    "\n",
    "def upload_to_yandex_disk(ya_token, file_path, remote_folder=\"/\"):\n",
    "    ya_disk = Yadisk(ya_token)\n",
    "    \n",
    "    try:\n",
    "        ya_disk.upload(file_path, remote_folder)\n",
    "        print(f\"Файл успешно загружен на Яндекс.Диск в папку '{remote_folder}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка при загрузке файла: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ya_token = \"ВАШ_ТОКЕН\"  # Получите токен на странице приложений Яндекса\n",
    "    file_path = \"generated_image.png\"  # Путь к изображению\n",
    "    remote_folder = \"/images/\"  # Папка на Яндекс.Диске, куда будет загружено изображение\n",
    "    \n",
    "    upload_to_yandex_disk(ya_token, file_path, remote_folder)\n",
    "```\n",
    "\n",
    "### Объяснение:\n",
    "\n",
    "1. **Yadisk**: Класс, представляющий подключение к Яндекс.Диску.\n",
    "2. **upload**: Метод, который загружает файл на Яндекс.Диск.\n",
    "\n",
    "### Как получить токен для доступа к Яндекс.Диску:\n",
    "\n",
    "1. Перейдите на страницу разработки приложений Яндекса: https://oauth.yandex.ru/client/new\n",
    "2. Выберите тип приложения \"Стандарты OAuth\" и заполните необходимые поля.\n",
    "3. После создания приложения получите токен доступа.\n",
    "\n",
    "После выполнения этих шагов, ваше изображение будет успешно загружено на Яндекс.Диск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После загрузки изображения на Яндекс.Диск, чтобы получить ссылку на него, можно воспользоваться методом `get_download_link()` библиотеки `yadisk`. Этот метод возвращает публичную ссылку, по которой можно скачать файл.\n",
    "\n",
    "Вот обновленный код, который включает получение ссылки на загруженное изображение:\n",
    "\n",
    "```python\n",
    "from yadisk import Yadisk\n",
    "\n",
    "def upload_and_get_link(ya_token, file_path, remote_folder=\"/\"):\n",
    "    ya_disk = Yadisk(ya_token)\n",
    "    \n",
    "    try:\n",
    "        ya_disk.upload(file_path, remote_folder)\n",
    "        print(f\"Файл успешно загружен на Яндекс.Диск в папку '{remote_folder}'.\")\n",
    "        \n",
    "        public_link = ya_disk.publish(remote_folder + file_path.split(\"/\")[-1])\n",
    "        download_link = public_link.get(\"href\", \"\")\n",
    "        print(f\"Ссылка на скачивание изображения: {download_link}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка при загрузке файла: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ya_token = \"ВАШ_ТОКЕН\"  # Получите токен на странице приложений Яндекса\n",
    "    file_path = \"generated_image.png\"  # Путь к изображению\n",
    "    remote_folder = \"/images/\"  # Папка на Яндекс.Диске, куда будет загружено изображение\n",
    "    \n",
    "    upload_and_get_link(ya_token, file_path, remote_folder)\n",
    "```\n",
    "\n",
    "### Объяснение изменений:\n",
    "\n",
    "1. **publish**: Метод делает файл общедоступным, возвращая словарь с информацией о ссылке.\n",
    "2. **get(\"href\", \"\")**: Извлекаем значение ключа `\"href\"` из словаря, которое содержит ссылку на скачивание файла.\n",
    "\n",
    "Теперь после загрузки изображения на Яндекс.Диск, программа выведет ссылку, по которой можно скачать файл."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
